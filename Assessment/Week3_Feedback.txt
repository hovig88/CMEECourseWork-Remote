Starting weekly assessment for Hovig, Week3

Current Points = 100

Note that: 
(1) Major sections begin with a double "====" line 
(2) Subsections begin with a single "====" line 
(3) Code output or text file content are printed within single "*****" lines 

======================================================================
======================================================================
Your Git repo size this week is about 137.28 MiB on disk 

PART 1: Checking project workflow...

Found the following directories in parent directory: Week6, Week1, Week7, Assessment, Week10, Week5, Week2, Week9, Week4, .git, Week3, MiniProject

Found the following files in parent directory: .gitignore, README.md

Checking for key files in parent directory...

Found .gitignore in parent directory, great! 

Printing contents of .gitignore:
**********************************************************************
*~
*.tmp
__pycache__/

# History files
.Rhistory
.Rapp.history

# Session Data files
.RData

# User-specific files
.Ruserdata

# Example code in package build process
*-Ex.R

# Output files from R CMD build
/*.tar.gz

# Output files from R CMD check
/*.Rcheck/

# RStudio files
.Rproj.user/

# produced vignettes
vignettes/*.html
vignettes/*.pdf

# OAuth2 token, see https://github.com/hadley/httr/releases/tag/v0.3
.httr-oauth

# knitr and R markdown default cache directories
*_cache/
/cache/

# Temporary files created by R markdown
*.utf8.md
*.knit.md
**********************************************************************

Found README in parent directory, named: README.md

Printing contents of README.md:
**********************************************************************
# Computational Methods in Ecology and Evolution (CMEE) Masters Program

* This repository includes weekly practicals/assignments and in-class scripts required for the partial completion of the CMEE Masters program.

* The **CMEECourseWork-Remote** directory contains a `.gitignore` file and subdirectories named as `Week1`, `Week2`,...etc. This will be updated weekly as the course progresses. 

## Contents

### Week 1

This directory includes code and data related to the first week's practicals/assignments and in-class scripts. 

In the first week, the following sections were covered:

* Unix
* Shell scripting
* Version control with Git
* Scientific documents with LaTeX

### Week 2

This directory includes code and data related to the second week's practicals/assignments and in-class scripts. 

In the second week, the following sections were covered:

* Biological computing in Python I

### Week 3

This directory includes code and data related to the third week's practicals/assignments and in-class scripts. 

In the third week, the following sections were covered:

* Biological Computing in R

### Week 4

This directory includes code and data related to the fourth week's practicals/assignments and in-class scripts. 

In the fourth week, the following sections were covered:

* Statistics in R
* CMEE Miniproject Start

### Week 5

This directory includes code and data related to the fifth week's practicals/assignments and in-class scripts. 

In the fifth week, the following sections were covered:

* Statistics in R
* Spatial Analyses and GIS
* CMEE Miniproject Start

### Week 6

This directory includes code and data related to the sixth week's practicals/assignments and in-class scripts. 

In the sixth week, the following sections were covered:

* Genomics and Bioinformatics

### Week 7

This directory includes code and data related to the seventh week's practicals/assignments and in-class scripts. 

In the seventh week, the following sections were covered:

* Biological Computing in Python II

### MiniProject (Week 8)

This directory includes code and data related to the eighth week's practicals/assignments and in-class scripts. 

In the eighth week, the following sections were covered:

* CMEE Miniproject: Hackathon

### Week 9

This directory includes code and data related to the ninth week's practicals/assignments and in-class scripts. 

In the ninth week, the following sections were covered:

* High Performance Computing

### Week 10

This directory includes code and data related to the tenth week's practicals/assignments and in-class scripts. 

In the tenth week, the following sections were covered:

* Biological Data Structures and C

## Authors

Jedi (in training): Hovig Artinian

Academic email: ha819@ic.ac.uk

Personal email: artinianhovig@gmail.com

## License

None

## Acknowledgements

I would like to thank Master Jedi Samraat Pawar for accepting me as his young padawan.
**********************************************************************

======================================================================
Looking for the weekly directories...

Found 9 weekly directories: Week1, Week10, Week2, Week3, Week4, Week5, Week6, Week7, Week9

The Week3 directory will be assessed 

======================================================================
======================================================================
PART 2: Checking weekly code and workflow...

======================================================================
Assessing WEEK3...

Found the following directories: code, sandbox, data, results

Found the following files: README.md

Checking for readme file in weekly directory...

Found README in parent directory, named: README.md

Printing contents of README.md:
**********************************************************************
# Week 3: CMEE Bootcamp: Biological Computing in R

* The third week was an introduction to the R programming language. It covered from performing simple operations, writing scripts and functions, data management, and data visualization.

* The **Week3** directory includes the following subdirectories: *code*, *data*, *results*, and *sandbox*.
    - code - includes all the Week 3 practicals/assignments and in-class scripts
    - data - includes the data needed as inputs for some of the scripts/commands
    - results - essentially an empty directory, but includes a .gitignore file (since completely empty directories cannnot be pushed to git)
    - sandbox - similar to a recycle bin; disposing files that are not needed for assessment, but might still be useful for the author if and when needed

## Contents

### Code

* apply1.R - application on the apply function
* apply2.R - application on the apply function
* Autocorrelation.tex - LaTeX format file that can be compiled to a pdf format using the `CompileLaTeX.sh` bash script from the `Week1` directory
* basic_io.R - illustrates R input-output
* boilerplate.R - basic boilerplate R script
* break.R - basic usage of break
* browse.R - basic usage of the browser function for debugging
* control_flow.R - basic control flow R script
* DataWrang.R - basic data management and wrangling workflow
* DataWrangTidy.R - basic data management and wrangling workflow using dplyr and tidyr
* get_TreeHeights.py - A python version of `get_TreeHeight.R`
* get_TreeHeights.R - A generic version of `TreeHeight.R`, where it takes any input file as a dataset
* Girko.R - plots the Girko's law simulation and saves it to a pdf file
* GPDD_Data.R - mapping the Global Population Dynamics Database (GPDD)
* MyBars.R - using ggplot geom text to annotate plot
* next.R - basic usage of the next function
* plotLin.R - annotates a plot and saves it to a pdf file
* PP_Lattice.R - this script creates three lattice graphs by feeding interaction type for predator mass, prey mass, and size ratio of prey mass over predator mass. It also calculates the mean and median predator mass, prey mass, and size rato to a csv file
* PP_Regress_loc.R - similar to the PP_Regress.R script, with the addition of the Location parameter
* PP_Regress.R - this script draws and saves a pdf file of an exact copy of a figure found in the chapter, and writes the accompanying regression results to a formatted table in csv
* preallocate.R - using preallocation approach to speed up for loops
* Ricker.R - runs a simulation of the Ricker model and returns a vector of length generations
* run_get_TreeHeight.sh - runs get_TreeHeight.R and get_TreeHeight.py scripts
* sample.R - an example of vectorization involving `lapply` and `sapply`
* TAutoCorr.R - this script calculates the coefficients of temperature correlations between successive years
* TreeHeight.R - This function calculates heights of trees given distance of each tree from its base and angle to its top, using  the trigonometric formula 
* try.R - debugging with try function
* Vectorize1.py - a python version of `Vectorize1.R`
* Vectorize1.R - an example of how usnig a vectorization approach can enhance the speed of a script
* Vectorize2.py - a python version of `Vectorize2.R`
* Vectorize2.R - runs the stochastic Ricker equation with gaussian fluctuations

### Data

* EcolArchives-E089-51-D1.csv - a dataset on Consumer-Resource (e.g., Predator-Prey) body mass ratios taken from the Ecological Archives of the ESA (Barnes et al. 2008, Ecology 89:881). 
* GPDDFiltered.RData - a filtered dataset of the Global Population Dynamics Database (GPDD).
* KeyWestAnnualMeanTemperature.RData - a dataset with temperatures in Key West, Florida for the 20th century
* PoundHillData.csv - a dataset on cultivation treatments applied in three months: october, may, march
* PoundHillMetaData.csv - metadata on the `PoundHillData.csv` dataset
* Results.txt - some data used in the `MyBars.py` script to show how plot annotation is done
* trees.csv - a dataset of tree species with their corresponding degrees (angle of elevation of tree) and distance (distance from base of tree in meters)
* Vectorize1_py.txt - stores time values obtained when running the functions in `Vectorize1_py` script
* Vectorize1_R.txt - stores time values obtained when running the functions in `Vectorize1_R` script
* Vectorize2_py.txt - stores time values obtained when running the functions in `Vectorize2_py` script
* Vectorize2_R.txt - stores time values obtained when running the functions in `Vectorize2_R` script

## Authors

Jedi (in training): Hovig Artinian

Academic email: ha819@ic.ac.uk

Personal email: artinianhovig@gmail.com

## License

None

## Acknowledgements

Third week of Jedi training completed!
**********************************************************************

Found following files in results directory: TreeHts.csv, Temp_Hist.pdf, trees_treeheights_py.csv, Girko.pdf, PP_Results.csv, PP_Regress_Results.csv, PP_Regress_loc_Results.csv, PP_Regress.pdf, Ricker.pdf, trees_treeheights.csv, Pred_Lattice.pdf, Prey_Lattice.pdf, MyLinReg.pdf, .gitignore, Temp_Plot.pdf, SizeRatio_Lattice.pdf, MyBars.pdf, MyData.csv...
ideally, Results directory should be empty other than, perhaps, a readme. 

Found 32 code files: browse.R, PP_Regress.R, Vectorize2.py, apply1.R, sample.R, control_flow.R, run_get_TreeHeight.sh, get_TreeHeight.py, GPDD_Data.R, boilerplate.R, TreeHeight.R, Autocorrelation.tex, PP_Lattice.R, next.R, Ricker.R, Girko.R, Vectorize1.R, break.R, plotLin.R, basic_io.R, Vectorize1.py, try.R, apply2.R, get_TreeHeight.R, TAutoCorr.R, Vectorize2.R, DataWrangTidy.R, preallocate.R, PP_Regress_loc.R, DataWrang.R, run_Vectorize.sh, MyBars.R

Found the following extra files: Rplots.pdf
0.5 pt deducted per extra file

Current Points = 99.5

======================================================================
Testing script/code files...

======================================================================
Inspecting script file browse.R...

File contents are:
**********************************************************************
#!/usr/bin/env R

Exponential <- function(N0 = 1, r = 1, generations = 10){
    # Runs a simulation of exponential growth
    # Returns a vector of length generations

    N <- rep(NA, generations)   # Creates a vector of NA

    N[1] <- N0
    for (t in 2:generations){
        N[t] <- N[t-1] * exp(r)
        browser()
    }
    return (N)
}

plot(Exponential(), type="l", main="Exponential growth")
**********************************************************************

Testing browse.R...

Output (only first 500 characters): 

**********************************************************************
Called from: Exponential()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()

**********************************************************************

Code ran without errors

Time consumed = 0.14590s

======================================================================
Inspecting script file PP_Regress.R...

File contents are:
**********************************************************************
#!/usr/bin/env R

# this script draws and saves a pdf file of an exact copy of a figure found in the chapter, and writes the accompanying regression results to a formatted table in csv

# import required packages
require(ggplot2, warn.conflicts = FALSE, quietly = TRUE)
require(plyr, quietly = TRUE)
require(broom, quietly = TRUE)

rm(list=ls())

# suppress unnecessary warning messages
options(warn = -1)

# fixing dataset
MyDF = read.csv("../data/EcolArchives-E089-51-D1.csv")
MyDF$Prey.mass[which(MyDF$Prey.mass.unit=="mg")] = MyDF$Prey.mass[which(MyDF$Prey.mass.unit=="mg")]/1000 # converting all prey massses to same unit
MyDF$Prey.mass.unit[which(MyDF$Prey.mass.unit=="mg")] = "g"

print("Plotting and saving the graph in a pdf file...", quote = FALSE)
ggplot(data = MyDF, aes(MyDF$Prey.mass, MyDF$Predator.mass)) +
geom_point(shape=I(3), aes(color = MyDF$Predator.lifestage)) +
facet_wrap(~ MyDF$Type.of.feeding.interaction, nrow=5, ncol=1, strip.position = "right") + # equivalent to the lattice command in qplot
geom_smooth(method = "lm", fullrange = TRUE, size = 0.5, aes(color = MyDF$Predator.lifestage)) + # draws a linear regression line
xlab("Prey Mass in grams") +
ylab("Predator mass in grams") +
theme_bw() + # black and white background
guides(col = guide_legend(nrow=1)) + # aligns the legends in 1 row
theme(panel.grid.minor = element_line(color = "gray96"), legend.title = element_text(size = 8, face = "bold"), legend.position = "bottom", 
      legend.key.size = unit(1, "line"), legend.text = element_text(size = 8), plot.margin=unit(c(1,3,1,3), "cm")) + # fixing the legend area
scale_x_continuous(trans="log10") + # scaling x
scale_y_continuous(trans="log10") + # scaling y
labs(color="Predator.lifestage") # remaming legend title

ggsave("../results/PP_Regress.pdf", plot = last_plot(), width = unit(7, "in"), height = unit(10, "in"), dpi = 500)

# creating a subset of the original dataset, showing a combination between feeding type and predator lifestage
subDF = data.frame("Feeding.type.X.Predator.lifestage" = paste(MyDF$Type.of.feeding.interaction, MyDF$Predator.lifestage), "Predator.mass" = MyDF$Predator.mass, "Prey.mass" = MyDF$Prey.mass)

print("Calculating the needed results...", quote = FALSE)
results = ddply(subDF, .(Feeding.type.X.Predator.lifestage), summarize,
              intercept = lm(log10(Predator.mass)~log10(Prey.mass))$coef[1],
              slope = lm(log10(Predator.mass)~log10(Prey.mass))$coef[2], 
              r.squared = summary(lm(log10(Predator.mass)~log10(Prey.mass)))$r.squared,
              f.statistic = as.numeric(glance(lm(log10(Predator.mass)~log10(Prey.mass)))[4]), # from broom package
              p.value = summary(lm(log10(Predator.mass)~log10(Prey.mass)))$coefficients[8])

print("Writing the results into a csv file...", quote = FALSE)
write.csv(results, "../results/PP_Regress_Results.csv", row.names = FALSE)

print("Done!", quote = FALSE)
**********************************************************************

Testing PP_Regress.R...

Output (only first 500 characters): 

**********************************************************************
[1] Plotting and saving the graph in a pdf file...
[1] Calculating the needed results...
[1] Writing the results into a csv file...
[1] Done!

**********************************************************************

Code ran without errors

Time consumed = 5.26190s

======================================================================
Inspecting script file Vectorize2.py...

File contents are:
**********************************************************************
#!/usr/bin/env python3

"""A python version of Vectorize2.R"""

__appname__ = 'Vectorize2.py'
__author__ = 'Hovig Artinian (ha819@imperial.ac.uk)'
__version__ = '0.0.1'
__license__ = 'None'

## imports ##
import scipy as sc
import numpy as np
import time
import sys

## functions ##
def stochrick (p0 = np.random.uniform(0.5,1.5,1000), r = 1.2, K = 1, sigma = 0.2, numyears = 100):
    """Runs a simulation of a stochastic Ricker model using nested for loops"""

    #initialize
    N = sc.zeros((numyears, len(p0)))
    N[0,:] = p0

    for pop in range(len(p0)): # loop through the populations
        for yr in np.arange(numyears-1)+1: # loop through the years
            N[yr,pop] = N[yr-1, pop] * np.exp(r * (1 - N[yr-1, pop] / K) + np.random.normal(0, sigma, 1))

    return(N)

def stochrickvect (p0 = np.random.uniform(0.5,1.5,1000), r = 1.2, K = 1, sigma = 0.2, numyears = 100):
    """Runs a simulation of a stochastic Ricker model using vectorization"""
    
    #initialize
    N = sc.zeros((numyears, len(p0)))
    N[0,:] = p0

    for yr in np.arange(numyears-1)+1:
        N[yr,:] = N[yr-1,:] * np.exp(r * (1 - N[yr-1,:] / K) + np.random.normal(0, sigma, 1)) # taking the whole row into consideration instead of row element by element

    return(N)

## main function ##
def main(argv):
    """The main function compares the computational speed of the stochrick 
    and stochrickvect functions."""

    # comparing the computational speeds of the two functions
    print("Using loops, the time taken is:")
    start_time1 = time.time()
    stochrick()
    elapsed_time1 = time.time() - start_time1
    print(round(elapsed_time1, 3))

    print("Using the in-built vectorized function, the time taken is:")
    start_time2 = time.time()
    stochrickvect()
    elapsed_time2 = time.time() - start_time2
    print(round(elapsed_time2, 3))

    # saving time values to be used later in the run_Vectorize.sh bash script
    f = open("../data/Vectorize2_py.txt", "w")
    f.write(str(round(elapsed_time1, 3)))
    f.write("\n")
    f.write(str(round(elapsed_time2, 3)))
    f.write("\n")
    f.close()

    return 0

if (__name__ == "__main__"):
    status = main(sys.argv)
    sys.exit(status)
**********************************************************************

Testing Vectorize2.py...

Vectorize2.py is a Python script file;

checking for docstrings...

Found one or more docstrings and functions

Current Points = 99.5

Output (only first 500 characters): 

**********************************************************************
Using loops, the time taken is:
0.703
Using the in-built vectorized function, the time taken is:
0.003

**********************************************************************

Code ran without errors

Time consumed = 0.84440s

======================================================================
Inspecting script file apply1.R...

File contents are:
**********************************************************************
#!/usr/bin/env R

## Build a random matrix
M <- matrix(rnorm(100), 10, 10)

## Take the mean of each row
RowMeans <- apply(M, 1, mean)
print (RowMeans)

## Now the variance
RowVars <- apply(M, 1, var)
print (RowVars)

## By column
ColMeans <- apply(M, 2, mean)
print (ColMeans)


SomeOperation <- function(v){ # (What does this function do?)
  if (sum(v) > 0){
    return (v * 100)
  }
  return (v)
}

M <- matrix(rnorm(100), 10, 10)
print (apply(M, 1, SomeOperation))
**********************************************************************

Testing apply1.R...

Output (only first 500 characters): 

**********************************************************************
 [1] -0.18037944  0.11022956 -0.07583839 -0.26488925 -0.10323364 -0.29505170
 [7]  0.67644137 -0.16469899 -0.19979782 -0.31238273
 [1] 1.6356103 0.3805606 0.7099572 0.6784901 0.8277819 0.7543169 0.3154581
 [8] 0.4635007 1.2797620 0.4631059
 [1] -0.44697894 -0.31833891  0.38265943 -0.20772316  0.09290360 -0.06819545
 [7]  0.57554366 -0.83748775 -0.13840331  0.15641980
            [,1]        [,2]       [,3]      [,4]        [,5]       [,6]
 [1,]  175.90243  0.59807967   94.90307 -32.14693 -41.7241
**********************************************************************

Code ran without errors

Time consumed = 0.12244s

======================================================================
Inspecting script file sample.R...

File contents are:
**********************************************************************
#!/usr/bin/env R

######### Functions ##########

## A function to make a sample of size n from a population "popn" and return its mean
myexperiment <- function(popn, n){
    pop_sample <- sample(popn, n, replace = FALSE)
    return(mean(pop_sample))   
}

## Calculate means using a for loop without preallocation:
loopy_sample1 <- function(popn, n, num){
    result1 <- vector() #Initialize empty vector of size 1
    for(i in 1:num){
        result1 <- c(result1, myexperiment(popn, n))
    }
        return(result1)
}

## To run "num" iterations of the experiment using a for loop on a vector with preallocation:
loopy_sample2 <- function(popn, n, num){
    result2 <- vector(,num) #Preallocate expected size
    for(i in 1:num){
        result2[i] <- myexperiment(popn, n)
    }
        return(result2)
}

## To run "num" iterations of the experiment using a for loop on a list with preallocaiton:
loopy_sample3 <- function(popn, n, num){
    result3 <-vector("list", num) #Preallocate expected size
    for(i in 1:num){
        result3[[i]] <- myexperiment(popn, n)
    }
        return(result3)
}

## To run "num" iterations of the experiment using vectorization with lapply:
lapply_sample <- function(popn, n, num){
    result4 <- lapply(1:num, function(i) myexperiment(popn, n))
    return(result4)
}

## To run "num" iterations of the experiment using vectorization with sapply:
sapply_sample <- function(popn, n, num){
    result5 <- sapply(1:num, function(i) myexperiment(popn, n))
    return(result5)
}

popn <- rnorm(1000) # Generate the population
hist(popn)

n <- 20 # sample size for each experiment
num <- 1000 # Number of times to rerun the experiment

print("The loopy, non-preallocation approach takes:" )
print(system.time(loopy_sample1(popn, n, num)))

print("The loopy, but with preallocation approach takes:" )
print(system.time(loopy_sample2(popn, n, num)))

print("The loopy, non-preallocation approach takes:" )
print(system.time(loopy_sample3(popn, n, num)))

print("The vectorized sapply approach takes:" )
print(system.time(sapply_sample(popn, n, num)))

print("The vectorized lapply approach takes:" )
print(system.time(lapply_sample(popn, n, num)))

**********************************************************************

Testing sample.R...

Output (only first 500 characters): 

**********************************************************************
[1] "The loopy, non-preallocation approach takes:"
   user  system elapsed 
  0.032   0.000   0.032 
[1] "The loopy, but with preallocation approach takes:"
   user  system elapsed 
  0.012   0.000   0.014 
[1] "The loopy, non-preallocation approach takes:"
   user  system elapsed 
  0.012   0.000   0.013 
[1] "The vectorized sapply approach takes:"
   user  system elapsed 
  0.012   0.000   0.010 
[1] "The vectorized lapply approach takes:"
   user  system elapsed 
  0.012   0.000   0.010 

**********************************************************************

Code ran without errors

Time consumed = 0.29182s

======================================================================
Inspecting script file control_flow.R...

File contents are:
**********************************************************************
#!/usr/bin/env R

## If statement
a <- TRUE
if (a == TRUE){
	print ("a is TRUE")
	} else {
	print ("a is FALSE")
}

## If statement on a single line
z <- runif(1) ## uniformly distributed random number
if (z <= 0.5) {print ("Less than a half")}

## For loop using a sequence
for (i in 1:10){
	j <- i * i
	print(paste(i, " squared is", j ))
}

## For loop over vector of strings
for(species in c('Heliodoxa rubinoides', 
                 'Boissonneaua jardini', 
                 'Sula nebouxii')){
  print(paste('The species is', species))
}

## for loop using a vector
v1 <- c("a","bc","def")
for (i in v1){
	print(i)
}

## While loop
i <- 0
while (i<10){
	i <- i+1
	print(i^2)
}
**********************************************************************

Testing control_flow.R...

Output (only first 500 characters): 

**********************************************************************
[1] "a is TRUE"
[1] "Less than a half"
[1] "1  squared is 1"
[1] "2  squared is 4"
[1] "3  squared is 9"
[1] "4  squared is 16"
[1] "5  squared is 25"
[1] "6  squared is 36"
[1] "7  squared is 49"
[1] "8  squared is 64"
[1] "9  squared is 81"
[1] "10  squared is 100"
[1] "The species is Heliodoxa rubinoides"
[1] "The species is Boissonneaua jardini"
[1] "The species is Sula nebouxii"
[1] "a"
[1] "bc"
[1] "def"
[1] 1
[1] 4
[1] 9
[1] 16
[1] 25
[1] 36
[1] 49
[1] 64
[1] 81
[1] 100

**********************************************************************

Code ran without errors

Time consumed = 0.12826s

======================================================================
Inspecting script file run_get_TreeHeight.sh...

File contents are:
**********************************************************************
#!/bin/bash
# Author: Hovig Artinian ha819@imperial.ac.uk
# Script: run_get_TreeHeight.sh
# Desc: runs get_TreeHeight.R and get_TreeHeight.py scripts
# Arguments: trees.csv
# Date: Oct 2019

echo -e "\nRunning R script...\n"
Rscript get_TreeHeight.R ../data/trees.csv

if [ $? ] # If script runs successfully, the stored value of $? will be 0, which makes the if statement TRUE
then
    echo -e "\nScript ran successfully!\n"
else
    echo -e "\nScript failed to run :(\n"
fi

echo -e "Running python script...\n"
python3 get_TreeHeight.py ../data/trees.csv

if [ $? ]
then
    echo -e "\nScript ran successfully!\n"
else
    echo -e "\nScript failed to run :(\n"
fi
**********************************************************************

Testing run_get_TreeHeight.sh...

Output (only first 500 characters): 

**********************************************************************

Running R script...

[1] Required input file provided...
[1] Calculating tree heights...
[1] Adding height column to original dataset...
[1] Saving the new dataset into a csv file...
[1] Done!

Script ran successfully!

Running python script...

Required input provided...
Calculating tree heights...
Adding height column to original dataset...
Saving the new dataset into a csv file...
Done!

Script ran successfully!


**********************************************************************

Code ran without errors

Time consumed = 0.26025s

======================================================================
Inspecting script file get_TreeHeight.py...

File contents are:
**********************************************************************
#!/usr/bin/env python3

"""A python version of get_TreeHeight.R"""

__appname__ = 'get_TreeHeight.py'
__author__ = 'Hovig Artinian (ha819@imperial.ac.uk)'
__version__ = '0.0.1'
__license__ = 'None'

## imports ##
import math
import sys
import csv
import numpy as np

## functions ##
def TreeHeight(degrees, distance):
    """This function calculates heights of trees given distance of each tree from its base and angle to its top, using the trigonometric formula."""
    radians = degrees * math.pi / 180
    tan_radians = np.array([math.tan(radians[i]) for i in range(len(radians))])
    height = distance * tan_radians
    return height.tolist()

def InputFile(args):
    """This function makes sure the script can handle input files, even if none are provided"""
    if(len(args)) == 1:
        print("No input file provided... taking default file...")
        file = "../data/trees.csv"
    elif(len(args)) == 2:
        print("Required input provided...")
        file = args[1]
    elif(len(args) >= 3):
        print("More than one file provided... taking the first one...")
        file = args[1]
    return file

file = InputFile(sys.argv)

TreesData = []

# Saving the file into a list
with open(file) as csv_file:
    csv_reader = csv.reader(csv_file, delimiter = ',')
    for row in csv_reader:
        TreesData.append(row)

print("Calculating tree heights...")
distance = np.array([float(TreesData[i][1]) for i in np.arange(len(TreesData)-1)+1])
degrees = np.array([float(TreesData[i][2]) for i in np.arange(len(TreesData)-1)+1])
height = TreeHeight(degrees, distance)

print("Adding height column to original dataset...")
for i in np.arange(len(TreesData)-1)+1:
    TreesData[i].append(height[i-1])

TreesData[0].append('Tree.Height.m')

print("Saving the new dataset into a csv file...")
InputFileName = file.split('/')[2].split('.')[0]
with open("../results/" + InputFileName + "_treeheights_py.csv", "w") as csv_file:
    csv_writer = csv.writer(csv_file)
    csv_writer.writerows(TreesData)

print("Done!")
**********************************************************************

Testing get_TreeHeight.py...

get_TreeHeight.py is a Python script file;

checking for docstrings...

Found one or more docstrings and functions

Current Points = 99.5

Output (only first 500 characters): 

**********************************************************************
No input file provided... taking default file...
Calculating tree heights...
Adding height column to original dataset...
Saving the new dataset into a csv file...
Done!

**********************************************************************

Code ran without errors

Time consumed = 0.14734s

======================================================================
Inspecting script file GPDD_Data.R...

File contents are:
**********************************************************************
#!/usr/bin/env R

# importing required packages
require(maps, quietly = TRUE)

# loading the GPDD data
load(file = '../data/GPDDFiltered.RData')

# creating a world map
map('world')
map.axes()

# localizing points on the map
points(x = gpdd$long, y  = gpdd$lat, pch = 8, cex = 0.25, col ='red')

print("The map produced from this script is biased since the data used claims to be a global representation, yet the majority of the samples in study come from European and North American countries.", quote = FALSE)
**********************************************************************

Testing GPDD_Data.R...

Output (only first 500 characters): 

**********************************************************************
[1] The map produced from this script is biased since the data used claims to be a global representation, yet the majority of the samples in study come from European and North American countries.

**********************************************************************

Code ran without errors

Time consumed = 0.21565s

======================================================================
Inspecting script file boilerplate.R...

File contents are:
**********************************************************************
#!/usr/bin/env R

# A boilerplate R script

MyFunction <- function(Arg1, Arg2){

  # Statements involving Arg1, Arg2:
  print(paste("Argument", as.character(Arg1), "is a", class(Arg1))) # print Arg1's type
  print(paste("Argument", as.character(Arg2), "is a", class(Arg2))) # print Arg2's type

  return (c(Arg1, Arg2)) #this is optional, but very useful
}

MyFunction(1,2) #test the function
MyFunction("Riki","Tiki") #A different test
**********************************************************************

Testing boilerplate.R...

Output (only first 500 characters): 

**********************************************************************
[1] "Argument 1 is a numeric"
[1] "Argument 2 is a numeric"
[1] 1 2
[1] "Argument Riki is a character"
[1] "Argument Tiki is a character"
[1] "Riki" "Tiki"

**********************************************************************

Code ran without errors

Time consumed = 0.11682s

======================================================================
Inspecting script file TreeHeight.R...

File contents are:
**********************************************************************
#!/usr/bin/env R

# This function calculates heights of trees given distance of each tree 
# from its base and angle to its top, using  the trigonometric formula 
#
# height = distance * tan(radians)
#
# ARGUMENTS
# degrees:   The angle of elevation of tree
# distance:  The distance from base of tree (e.g., meters)
#
# OUTPUT
# The heights of the tree, same units as "distance"

TreeHeight <- function(degrees, distance){
  radians <- degrees * pi / 180
  height <- distance * tan(radians)

  return (height)
}

TreesData = read.csv("../data/trees.csv") # storing the csv file in a variable
print("Calculating tree heights...", quote = FALSE)
height = as.data.frame(TreeHeight(TreesData[,3], TreesData[,2])) # storing the values of the heights into a variable
colnames(height) = "Tree.Height.m"

print("Adding height column to original dataset...", quote = FALSE)
TreeHts = cbind(TreesData, height)

print("Saving the new dataset into a csv file...", quote = FALSE)
write.csv(TreeHts, "../results/TreeHts.csv", row.names = F)

print("Done!", quote = FALSE)
**********************************************************************

Testing TreeHeight.R...

Output (only first 500 characters): 

**********************************************************************
[1] Calculating tree heights...
[1] Adding height column to original dataset...
[1] Saving the new dataset into a csv file...
[1] Done!

**********************************************************************

Code ran without errors

Time consumed = 0.11351s

======================================================================
Inspecting script file Autocorrelation.tex...

File contents are:
**********************************************************************
\documentclass[12pt]{article}

\usepackage[top=10mm,bottom=25mm,left = 25mm , right = 25mm]{geometry}
\usepackage{pdfpages}
\usepackage{grffile}
\graphicspath{{../results/}}
\usepackage{caption}
\captionsetup{font=footnotesize}

\title{Autocorrelation in Weather}

\author{Hovig Artinian}

\date{October 24, 2019}

\begin{document}
    \maketitle
  
    \section{Aim}
        This practical deals with a dataset that includes temperature data in Key West, Florida during the 20th century.
        The aim is to prove whether or not there is a significant correlation between temperatures of successive years, across years.

    \section{Results}
    Upon plotting the values of the temperature as a function of years, we get the following output:
    \begin{figure}[h]
    \includegraphics[width = \linewidth, scale = 0.75]{Temp_Plot.pdf}
    \centering
    \caption[scale = 0.5]{Times series of temperature. The circles represent data values. The connecting lines were included to better visualize the trend in the time series.}
    \label{plot}
    \end{figure}
    
    Figure \ref{plot}\ shows no significant data, such as seasonal patterns or cyclic movements. There are no outliers and sudden shifts as well. The only observation worth mentioning is the increasing trend of the curve, which may be the result of climate change.

    The correlation coefficient between successive years was found to be 0.326. This value will be useful for analysis later.

    Next, we randomly permute the time series (10000 times!) and recalculate the correlation coefficient for each of these random permutations.\\
    
    Figure \ref{hist}\ below plots a histogram of the temperature correlations:
    \begin{figure}[h]
    \includegraphics[scale = 0.7]{Temp_Hist.pdf}
    \centering
    \caption{Histogram of temperature correlation. The red dashed line marks the location of the correlation coefficient of the real original dataset}
    \label{hist}
    \end{figure}

    A clear normal distribution is observed, with the mean almost close to zero.

    \section{Conclusion}
    \begin{itemize}
        \item The low value of the correlation coefficient indicates a weak correlation of temperatures betweens successive years.
        \item The p-value, which changes due to randomization, always seems to be very low.
        \item In Figure 2, the mean (= 0) of the correlation coefficients of the randomized permutations is far from the actual correlation value (= 0.326), which implies that the probability of random correlation of these temperatures is very low.
    \end{itemize}

    Based on the values of the original correlation coefficient and the p-value, there is a significantly weak correlation in temperature, which is reinforced by Figure 2.
\end{document}
**********************************************************************

Testing Autocorrelation.tex...

======================================================================
Inspecting script file PP_Lattice.R...

File contents are:
**********************************************************************
#!/usr/bin/env R

# this script creates three lattice graphs by feeding interaction type for predator mass, prey mass, and size ratio of prey mass over predator mass.
# It also calculates the mean and median predator mass, prey mass, and size rato to a csv file

# importing required packages
library(lattice)

# fixing dataset
MyDF <- read.csv("../data/EcolArchives-E089-51-D1.csv")
MyDF$Prey.mass[which(MyDF$Prey.mass.unit=="mg")] = MyDF$Prey.mass[which(MyDF$Prey.mass.unit=="mg")]/1000 # converting all prey massses to same unit
MyDF$Prey.mass.unit[which(MyDF$Prey.mass.unit=="mg")] = "g"

print("Creating and saving lattice graphs into pdf files...", quote = FALSE)
pdf("../results/Pred_Lattice.pdf")
densityplot(~log(Predator.mass) | Type.of.feeding.interaction, data=MyDF)
graphics.off()
pdf("../results/Prey_Lattice.pdf")
densityplot(~log(Prey.mass) | Type.of.feeding.interaction, data=MyDF)
graphics.off()
pdf("../results/SizeRatio_Lattice.pdf")
densityplot(~log(Prey.mass/Predator.mass) | Type.of.feeding.interaction, data=MyDF)
graphics.off()

print("Calculating mean and median...", quote = FALSE)
Feeding.Type=names(table(MyDF$Type.of.feeding.interaction))
Predator.Mass.Mean=tapply(log(MyDF$Predator.mass), MyDF$Type.of.feeding.interaction, mean)
Predator.Mass.Median=tapply(log(MyDF$Predator.mass), MyDF$Type.of.feeding.interaction, median)
Prey.Mass.Mean=tapply(log(MyDF$Prey.mass), MyDF$Type.of.feeding.interaction, mean)
Prey.Mass.Median=tapply(log(MyDF$Prey.mass), MyDF$Type.of.feeding.interaction, median)
SizeRatio.Mean=tapply(log(MyDF$Prey.mass/MyDF$Predator.mass), MyDF$Type.of.feeding.interaction, mean)
SizeRatio.Median=tapply(log(MyDF$Prey.mass/MyDF$Predator.mass), MyDF$Type.of.feeding.interaction, median)

# constructing the dataframe with the mean and median values
d = as.data.frame(cbind(Feeding.Type, Predator.Mass.Mean, Predator.Mass.Median, Prey.Mass.Mean, Prey.Mass.Median, SizeRatio.Mean, SizeRatio.Median))

print("Saving the results into a csv file...", quote = FALSE)
write.csv(d, "../results/PP_Results.csv", row.names = FALSE, quote = FALSE)

print("Done!", quote = FALSE)
**********************************************************************

Testing PP_Lattice.R...

Output (only first 500 characters): 

**********************************************************************
[1] Creating and saving lattice graphs into pdf files...
[1] Calculating mean and median...
[1] Saving the results into a csv file...
[1] Done!

**********************************************************************

Code ran without errors

Time consumed = 3.11831s

======================================================================
Inspecting script file next.R...

File contents are:
**********************************************************************
#!/usr/bin/env R

for (i in 1:10) {
    if ((i %% 2) == 0)
        next # pass to next iteration of loop
    print(i)
}**********************************************************************

Testing next.R...

Output (only first 500 characters): 

**********************************************************************
[1] 1
[1] 3
[1] 5
[1] 7
[1] 9

**********************************************************************

Code ran without errors

Time consumed = 0.12467s

======================================================================
Inspecting script file Ricker.R...

File contents are:
**********************************************************************
#!/usr/bin/env R

Ricker <- function(N0=1, r=1, K=10, generations=50)
{
    # Runs a simulation of the Ricker model
    # Returns a vector of length generations

    N <- rep(NA, generations)   # Create a vector of NA

    N[1] <- N0
    for (t in 2:generations)
    {
        N[t] <- N[t-1] * exp(r*(1.0-(N[t-1]/K)))
    }
    return (N)
}

print("Plotting and saving Ricker model...", quote = FALSE)
pdf("../results/Ricker.pdf")
plot(Ricker(generations=10), type="l")
graphics.off()

print("Done!", quote = FALSE)
**********************************************************************

Testing Ricker.R...

Output (only first 500 characters): 

**********************************************************************
[1] Plotting and saving Ricker model...
[1] Done!

**********************************************************************

Code ran without errors

Time consumed = 0.16665s

======================================================================
Inspecting script file Girko.R...

File contents are:
**********************************************************************
#!/usr/bin/env R

library(ggplot2)

build_ellipse <- function(hradius, vradius){ # function that returns an ellipse
  npoints = 250
  a <- seq(0, 2 * pi, length = npoints + 1)
  x <- hradius * cos(a)
  y <- vradius * sin(a)  
  return(data.frame(x = x, y = y))
}

N <- 250 # Assign size of the matrix

M <- matrix(rnorm(N * N), N, N) # Build the matrix

eigvals <- eigen(M)$values # Find the eigenvalues

eigDF <- data.frame("Real" = Re(eigvals), "Imaginary" = Im(eigvals)) # Build a dataframe

my_radius <- sqrt(N) # The radius of the circle is sqrt(N)

ellDF <- build_ellipse(my_radius, my_radius) # Dataframe to plot the ellipse

names(ellDF) <- c("Real", "Imaginary") # rename the columns

print("Creating the plot...", quote = FALSE)
# plot the eigenvalues
p <- ggplot(eigDF, aes(x = Real, y = Imaginary))
p <- p +
  geom_point(shape = I(3)) +
  theme(legend.position = "none")

# now add the vertical and horizontal line
p <- p + geom_hline(aes(yintercept = 0))
p <- p + geom_vline(aes(xintercept = 0))

# finally, add the ellipse
p <- p + geom_polygon(data = ellDF, aes(x = Real, y = Imaginary, alpha = 1/20, fill = "red"))

print("Saving the plot to a pdf file...", quote = FALSE)
pdf("../results/Girko.pdf")
print(p)
graphics.off()

print("Done!", quote = FALSE)
**********************************************************************

Testing Girko.R...

Output (only first 500 characters): 

**********************************************************************
[1] Creating the plot...
[1] Saving the plot to a pdf file...
[1] Done!

**********************************************************************

Code ran without errors

Time consumed = 1.42183s

======================================================================
Inspecting script file Vectorize1.R...

File contents are:
**********************************************************************
#!/usr/bin/env R

# compares the computational speed between functions containing nested for loops and vectorized functions

#initialize
M <- matrix(runif(1000000),1000,1000)

SumAllElements <- function(M){
  Dimensions <- dim(M)
  Tot <- 0
  for (i in 1:Dimensions[1]){ # loop through the rows
    for (j in 1:Dimensions[2]){ # loop through the columns
      Tot <- Tot + M[i,j] # add value of element to total sum of elements
    }
  }
  return (Tot)
}

# comparing computational speeds 
print("Using loops, the time taken is:", quote = FALSE)
time1 = print(system.time(SumAllElements(M)))

print("Using the in-built vectorized function, the time taken is:", quote = FALSE)
time2 = print(system.time(sum(M)))

# saving time values to be used later in the run_Vectorize.sh bash script
write.table(c(time1[[3]], time2[[3]]), "../data/Vectorize1_R.txt", row.names = FALSE, col.names = FALSE)
**********************************************************************

Testing Vectorize1.R...

Output (only first 500 characters): 

**********************************************************************
[1] Using loops, the time taken is:
   user  system elapsed 
  0.076   0.000   0.080 
[1] Using the in-built vectorized function, the time taken is:
   user  system elapsed 
  0.000   0.000   0.001 

**********************************************************************

Code ran without errors

Time consumed = 0.25993s

======================================================================
Inspecting script file break.R...

File contents are:
**********************************************************************
#!/usr/bin/env R

i <- 0 #Initialize i
while(i < Inf){
    if (i == 10) {
        print("i reached 10... breaking out of the while loop...", quote = FALSE)
        break
    } # Break out of the while loop!
    else {
        cat("i equals ", i, " \n")
        i <- i + 1 # Update i
    }
}
**********************************************************************

Testing break.R...

Output (only first 500 characters): 

**********************************************************************
i equals  0  
i equals  1  
i equals  2  
i equals  3  
i equals  4  
i equals  5  
i equals  6  
i equals  7  
i equals  8  
i equals  9  
[1] i reached 10... breaking out of the while loop...

**********************************************************************

Code ran without errors

Time consumed = 0.12565s

======================================================================
Inspecting script file plotLin.R...

File contents are:
**********************************************************************
#!/usr/bin/env R

# annotates a plot and saves it to a pdf file

library(ggplot2)

x <- seq(0, 100, by = 0.1)
y <- -4. + 0.25 * x +
  rnorm(length(x), mean = 0., sd = 2.5)

# and put them in a dataframe
my_data <- data.frame(x = x, y = y)

# perform a linear regression
my_lm <- summary(lm(y ~ x, data = my_data))

# plot the data
print("Plotting data...", quote = FALSE)
p <-  ggplot(my_data, aes(x = x, y = y,
                          colour = abs(my_lm$residual))
             ) +
  geom_point() +
  scale_colour_gradient(low = "black", high = "red") +
  theme(legend.position = "none") +
  scale_x_continuous(
    expression(alpha^2 * pi / beta * sqrt(Theta)))

# add the regression line
p <- p + geom_abline(
  intercept = my_lm$coefficients[1][1],
  slope = my_lm$coefficients[2][1],
  colour = "red")
# throw some math on the plot
p <- p + geom_text(aes(x = 60, y = 0,
                       label = "sqrt(alpha) * 2* pi"), 
                       parse = TRUE, size = 6, 
                       colour = "blue")

print("Saving data to a pdf file...", quote = FALSE)
print("Done!", quote = FALSE)

pdf("../results/MyLinReg.pdf")
print(p)
graphics.off()
**********************************************************************

Testing plotLin.R...

Output (only first 500 characters): 

**********************************************************************
[1] Plotting data...
[1] Saving data to a pdf file...
[1] Done!

**********************************************************************

Code ran without errors

Time consumed = 1.34373s

======================================================================
Inspecting script file basic_io.R...

File contents are:
**********************************************************************
#!/usr/bin/env R

# a simple script to illustrate R input-output.
# Run line by line and check inputs outputs to understand what is happening

options(warn=-1)

print("Importing trees.csv file...", quote = FALSE)
MyData <- read.csv("../data/trees.csv", header = TRUE) # import with headers

print("Writing it out as a new file...", quote = FALSE)
write.csv(MyData, "../results/MyData.csv") #write it out as a new file

print("Modifying dataset...", quote = FALSE)
write.table(MyData[1,], file = "../results/MyData.csv", append=TRUE) # Append to it
write.csv(MyData, "../results/MyData.csv", row.names=TRUE) # write row names
write.table(MyData, "../results/MyData.csv", col.names=FALSE) # ignore column names

print("Done!", quote = FALSE)
**********************************************************************

Testing basic_io.R...

Output (only first 500 characters): 

**********************************************************************
[1] Importing trees.csv file...
[1] Writing it out as a new file...
[1] Modifying dataset...
[1] Done!

**********************************************************************

Code ran without errors

Time consumed = 0.11409s

======================================================================
Inspecting script file Vectorize1.py...

File contents are:
**********************************************************************
#!/usr/bin/env python3

"""A python version of Vectorize1.R"""

__appname__ = 'Vectorize1.py'
__author__ = 'Hovig Artinian (ha819@imperial.ac.uk)'
__version__ = '0.0.1'
__license__ = 'None'

## imports ##
import numpy as np
import time
import sys

## functions ##
def SumAllElements(M):
    """This function sums all elements of a matrix"""
    Dimensions = M.shape # returns dimensions of matrix
    Tot = 0
    for i in np.arange(Dimensions[0]): # loop through the rows
        for j in np.arange((Dimensions[1])): # loop through the columns
            Tot = Tot + M.item(i, j) # add value of element to total sum of elements

    return(Tot)

## main function ##
def main(argv):
    """The main function compares the computational speed of the SumAllElements 
    function and the built-in numpy matrix sum function."""

    # initialize a matrix
    M = np.random.random((1000, 1000))
    M = np.matrix(M)
    
    # comparing computational speeds
    print("Using loops, the time taken is:")
    start_time1 = time.time()
    SumAllElements(M)
    elapsed_time1 = time.time() - start_time1
    print(round(elapsed_time1, 3))

    print("Using the in-built vectorized function, the time taken is:")
    start_time2 = time.time()
    np.matrix.sum(M)
    elapsed_time2 = time.time() - start_time2
    print(round(elapsed_time2, 3))

    # saving time values to be used later in the run_Vectorize.sh bash script
    f = open("../data/Vectorize1_py.txt", "w")
    f.write(str(round(elapsed_time1, 3)))
    f.write("\n")
    f.write(str(round(elapsed_time2, 3)))
    f.write("\n")
    f.close()

    return 0

if (__name__ == "__main__"):
    status = main(sys.argv)
    sys.exit(status)
**********************************************************************

Testing Vectorize1.py...

Vectorize1.py is a Python script file;

checking for docstrings...

Found one or more docstrings and functions

Current Points = 99.5

Output (only first 500 characters): 

**********************************************************************
Using loops, the time taken is:
0.226
Using the in-built vectorized function, the time taken is:
0.001

**********************************************************************

Code ran without errors

Time consumed = 0.38549s

======================================================================
Inspecting script file try.R...

File contents are:
**********************************************************************
#!/usr/bin/env R

doit <- function(x){
	temp_x <- sample(x, replace = TRUE)
	if(length(unique(temp_x)) > 30) {#only take mean if sample was sufficient
		 print(paste("Mean of this sample was:", as.character(mean(popn))))
		} 
	else {
		stop("Couldn't calculate mean: too few unique values!")
		}
	}

popn <- rnorm(50)

#Try doing the same thing using try
result <- lapply(1:15, function(i) try(doit(popn), F))

#This is a list that stores the result of each of the 15 runs, including the ones that ran into an error.
class(result)

result <- vector("list", 15) #Preallocate/Initialize
for(i in 1:15) {
	result[[i]] <- try(doit(popn), FALSE)
}
**********************************************************************

Testing try.R...

Output (only first 500 characters): 

**********************************************************************
[1] "Mean of this sample was: -0.350170441608684"
[1] "Mean of this sample was: -0.350170441608684"
[1] "Mean of this sample was: -0.350170441608684"
[1] "Mean of this sample was: -0.350170441608684"
[1] "Mean of this sample was: -0.350170441608684"
[1] "Mean of this sample was: -0.350170441608684"
[1] "Mean of this sample was: -0.350170441608684"
[1] "Mean of this sample was: -0.350170441608684"
[1] "Mean of this sample was: -0.350170441608684"
[1] "Mean of this sample was: -0.350170441608684"
[
**********************************************************************

Encountered error (or warning):
Error in doit(popn) : Couldn't calculate mean: too few unique values!
Error in doit(popn) : Couldn't calculate mean: too few unique values!
Error in doit(popn) : Couldn't calculate mean: too few unique values!
Error in doit(popn) : Couldn't calculate mean: too few unique values!
Error in doit(popn) : Couldn't calculate mean: too few unique values!
Error in doit(popn) : Couldn't calculate mean: too few unique values!
Error in doit(popn) : Couldn't calculate mean: too few unique values!
Error in doit(popn) : Couldn't calculate mean: too few unique values!

======================================================================
Inspecting script file apply2.R...

File contents are:
**********************************************************************
#!/usr/bin/env R

SomeOperation <- function(v){ # (What does this function do?)
    if (sum(v) > 0){
        return (v * 100)
    }
    return (v)
}

M <- matrix(rnorm(100), 10, 10)
print (apply(M, 1, SomeOperation))
**********************************************************************

Testing apply2.R...

Output (only first 500 characters): 

**********************************************************************
           [,1]        [,2]        [,3]       [,4]      [,5]        [,6]
 [1,] -56.93610  130.826725 -0.07080371 -0.3849852  22.60800 -1.24090837
 [2,]  84.20134  -32.070950  0.02797269 -1.5463731 -91.57340 -0.89319168
 [3,] -47.13807    4.988854  1.84424443  0.3765149 -36.18660  0.40029155
 [4,]  24.86334   35.831084 -0.72659903 -0.3055047 116.81497 -1.75465739
 [5,]  82.17813  -43.061766 -0.48451033  0.3815148 190.23625 -0.69959283
 [6,]  79.06446  -41.875849  1.02340075  0.8794082 -99.71900  2
**********************************************************************

Code ran without errors

Time consumed = 0.12875s

======================================================================
Inspecting script file get_TreeHeight.R...

File contents are:
**********************************************************************
#!/usr/bin/env R

# A generic version of TreeHeight.R, where it takes any input file as a dataset

TreeHeight <- function(degrees, distance){
  radians <- degrees * pi / 180
  height <- distance * tan(radians)

  return (height)
}

args = commandArgs(trailingOnly=TRUE)

if (length(args)==0) {
  print("No input file provided... taking default file...", quote = FALSE)
  args[1] = "../data/trees.csv"
} else if (length(args)==1) {
  print("Required input file provided...", quote = FALSE)
} else if (length(args) >= 2) {
  print("More than one file provided... taking the first one...", quote = FALSE)
}

TreesData = read.csv(args[1]) # storing the csv file in a variable

print("Calculating tree heights...", quote = FALSE)
height = as.data.frame(TreeHeight(TreesData[,3], TreesData[,2])) # storing the values of the heights into a variable
colnames(height) = "Tree.Height.m"

print("Adding height column to original dataset...", quote = FALSE)
TreeHts = cbind(TreesData, height)

print("Saving the new dataset into a csv file...", quote = FALSE)
InputFileName = sub(pattern = "(.*)\\..*$", replacement= "\\1", basename(args[1])) # stripping the extension and relative path from the file name
write.csv(TreeHts, paste0("../results/", InputFileName, "_treeheights.csv"), row.names = F)

print("Done!", quote = FALSE)
**********************************************************************

Testing get_TreeHeight.R...

Output (only first 500 characters): 

**********************************************************************
[1] No input file provided... taking default file...
[1] Calculating tree heights...
[1] Adding height column to original dataset...
[1] Saving the new dataset into a csv file...
[1] Done!

**********************************************************************

Code ran without errors

Time consumed = 0.11530s

======================================================================
Inspecting script file TAutoCorr.R...

File contents are:
**********************************************************************
#!/usr/bin/env R

# this script calculates the coefficients of temperature correlations between successive years

# loading dataset
load("../data/KeyWestAnnualMeanTemperature.RData")

# plotting the time series and saving the image in a pdf format
pdf("../results/Temp_Plot.pdf", height = 4)
plot(ats$Year, ats$Temp, main = "Temperature in Key West, Florida for the 20th Century", xlab = "Years", ylab = "Temperatures", type = "b")
graphics.off()

# creating two vectors in a (n, n-1) pairing format
x_t0 = ats$Temp[-100]
x_t1 = ats$Temp[-1]

# calculating the correlation coefficient of these pairs
c1 = format(round(cor(x_t0, x_t1), 3), nsmall = 3)
print(paste("The value of the correlation coefficient is", c1), quote = FALSE)

# for loop which calculates correlation coefficients in a variable
temp_cor = rep(NA, 10000)
for(i in 1:10000){ #looping 10000 times!
    test = sample(ats$Temp, replace = FALSE) # random permutations to test for randomness
    temp_cor[i] = cor(test[-100], test[-1]) # storing the values inside a variable
}

# plotting and saving the histogram of the temperature correlation coefficients in a pdf file
pdf("../results/Temp_Hist.pdf")
hist(temp_cor, main = "Temperature Correlation", xlab = "Correlation")
abline(v = cor(x_t0, x_t1), lty = 2, col = "red")
graphics.off()

# calculating the p-value
pVal = format(length(which(temp_cor > cor(x_t0, x_t1)))/length(which(temp_cor < cor(x_t0, x_t1))), scientific = TRUE)
print(paste("The approximate p-value of the graph is", pVal), quote = FALSE)

print("To find out more about the report analysis of these results, please refer to the Autocorrelation.pdf file, which can be generated by converting the Autocorrelation.tex file into a pdf file.", quote = FALSE)
**********************************************************************

Testing TAutoCorr.R...

Output (only first 500 characters): 

**********************************************************************
[1] The value of the correlation coefficient is 0.326
[1] The approximate p-value of the graph is 3.0009e-04
[1] To find out more about the report analysis of these results, please refer to the Autocorrelation.pdf file, which can be generated by converting the Autocorrelation.tex file into a pdf file.

**********************************************************************

Code ran without errors

Time consumed = 0.64086s

======================================================================
Inspecting script file Vectorize2.R...

File contents are:
**********************************************************************
#!/usr/bin/env R

# Runs the stochastic Ricker equation with gaussian fluctuations

rm(list=ls())

stochrick<-function(p0 = runif(1000, 0.5, 1.5), r = 1.2, K = 1, sigma = 0.2, numyears = 100)
{
  #initialize
  N<-matrix(NA,numyears,length(p0))
  N[1,]<-p0
  
  for (pop in 1:length(p0)){#loop through the populations
    
    for (yr in 2:numyears){ #for each pop, loop through the years

      N[yr,pop] <- N[yr-1,pop] * exp(r * (1 - N[yr - 1,pop] / K) + rnorm(1,0,sigma))
    
    }
  
  }
 return(N)

}

# same function as above, but with improved performance

stochrickvect<-function(p0=runif(1000,.5,1.5),r=1.2,K=1,sigma=0.2,numyears=100)
{
  #initialize
  N<-matrix(NA,numyears,length(p0))
  N[1,]<-p0
    
  for (yr in 2:numyears){ #for each pop, loop through the years
    N[yr,] <- N[yr-1,] * exp(r * (1 - N[yr - 1,] / K) + rnorm(1,0,sigma)) # taking the whole row into consideration instead of row element by element
  }
 
  return(N)

}

# comparing the computational speeds of the two functions
s1 = system.time(res1<-stochrick())[3] # store elapsed time of stochrick() function in a variable s1
print(paste("Non-vectorized Stochastic Ricker takes", as.numeric(format(round(s1, 3), nsmall = 2)), "seconds."), quote = FALSE)

s2 = system.time(res2<-stochrickvect())[3] # store elapsed time of stochrickvect() function in variable s2
print(paste("Vectorized Stochastic Ricker takes", as.numeric(format(round(s2, 3), nsmall = 2)), "seconds."), quote = FALSE)

ratio = s1/s2 # calculates the ratio of the elapsed times of the two functions
ratio = as.numeric(format(round(ratio, 3), nsmall = 2)) # formatting the ratio value to output only two digits after the decimal point
print(paste("Vectorizing the function reduced its speed by a magnitude of", ratio), quote = FALSE)

# saving time values to be used later in the run_Vectorize.sh bash script
write.table(c(as.numeric(format(round(s1, 3), nsmall = 2)), as.numeric(format(round(s2, 3), nsmall = 2))), "../data/Vectorize2_R.txt", row.names = FALSE, col.names = FALSE)
**********************************************************************

Testing Vectorize2.R...

Output (only first 500 characters): 

**********************************************************************
[1] Non-vectorized Stochastic Ricker takes 0.24 seconds.
[1] Vectorized Stochastic Ricker takes 0.011 seconds.
[1] Vectorizing the function reduced its speed by a magnitude of 21.818

**********************************************************************

Code ran without errors

Time consumed = 0.37279s

======================================================================
Inspecting script file DataWrangTidy.R...

File contents are:
**********************************************************************
#!/usr/bin/env R

################################################################
################## Wrangling the Pound Hill Dataset ############
################################################################

############### import packages ###############

require(dplyr, warn.conflicts = FALSE, quietly = TRUE)
require(tidyr, warn.conflicts = FALSE, quietly = TRUE)

############# Load the dataset ###############

# header = false because the raw data don't have real headers
MyData <- as.matrix(read.csv("../data/PoundHillData.csv",header = F)) 

# header = true because we do have metadata headers
MyMetaData <- read.csv("../data/PoundHillMetaData.csv",header = T, sep=";", stringsAsFactors = F)

############# Inspect the dataset ###############

print("Inspecting the dataset:", quote = FALSE)
glimpse(MyData)

############# Transpose ###############
# To get those species into columns and treatments into rows

MyData <- t(MyData) 

############# Replace species absences with zeros ###############

MyData[MyData == ""] = 0

############# Convert raw matrix to data frame ###############

TempData <- as.data.frame(MyData[-1,],stringsAsFactors = F) #stringsAsFactors = F is important!
colnames(TempData) <- MyData[1,] # assign column names from original data

############# Convert from wide to long format  ###############

MyWrangledData <- gather(TempData, key = "Species", value = "Count", colnames(TempData[,-(1:4)]),factor_key = TRUE) 
# compresses all columns referring to a species into one column and generates a count value for each species, storing them in a new column

MyWrangledData[, "Cultivation"] <- as.factor(MyWrangledData[, "Cultivation"])
MyWrangledData[, "Block"] <- as.factor(MyWrangledData[, "Block"])
MyWrangledData[, "Plot"] <- as.factor(MyWrangledData[, "Plot"])
MyWrangledData[, "Quadrat"] <- as.factor(MyWrangledData[, "Quadrat"])
MyWrangledData[, "Count"] <- as.integer(MyWrangledData[, "Count"])

print("Inspecting the wrangled dataset:",  quote = FALSE)
glimpse(MyWrangledData)
**********************************************************************

Testing DataWrangTidy.R...

Output (only first 500 characters): 

**********************************************************************
[1] Inspecting the dataset:
 chr [1:45, 1:60] "Cultivation" "Block" "Plot" "Quadrat" ...
 - attr(*, "dimnames")=List of 2
  ..$ : NULL
  ..$ : chr [1:60] "V1" "V2" "V3" "V4" ...
[1] Inspecting the wrangled dataset:
Observations: 2,419
Variables: 6
$ Cultivation <fct> october, october, october, october, october, may, may, ma…
$ Block       <fct> a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, b, b, b, …
$ Plot        <fct> 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, …
$ Quadrat     <f
**********************************************************************

Code ran without errors

Time consumed = 0.54900s

======================================================================
Inspecting script file preallocate.R...

File contents are:
**********************************************************************
#!/usr/bin/env R

# without pre-allocation
a <- NA
print(system.time(
    for (i in 1:10000) {
        a <- c(a, i)
        # print(a)
        # print(object.size(a))
    }
))

# with pre-allocate
a <- rep(NA, 10000)
print(system.time(
    for (i in 1:10000) {
    a[i] <- i
    # print(a)
    # print(object.size(a))
    }
))**********************************************************************

Testing preallocate.R...

Output (only first 500 characters): 

**********************************************************************
   user  system elapsed 
  0.148   0.032   0.152 
   user  system elapsed 
  0.004   0.000   0.003 

**********************************************************************

Code ran without errors

Time consumed = 0.27453s

======================================================================
Inspecting script file PP_Regress_loc.R...

File contents are:
**********************************************************************
#!/usr/bin/env R

# similar to the PP_Regress.R script, with the addition of the Location parameter

# importing required packages
require(plyr, quietly = TRUE)
require(broom, quietly = TRUE)

rm(list=ls())

# suppress unnecessary warning messages
options(warn=-1)

# fixing dataset
MyDF = read.csv("../data/EcolArchives-E089-51-D1.csv")
MyDF$Prey.mass[which(MyDF$Prey.mass.unit=="mg")] = MyDF$Prey.mass[which(MyDF$Prey.mass.unit=="mg")]/1000
MyDF$Prey.mass.unit[which(MyDF$Prey.mass.unit=="mg")] = "g"

# creating a subset of the original dataset, showing a combination between feeding type, predator lifestage, and location
subDF = data.frame("Feeding.type.X.Predator.lifestage.X.Location" = paste(MyDF$Type.of.feeding.interaction, MyDF$Predator.lifestage, MyDF$Location), "Predator.mass" = MyDF$Predator.mass, "Prey.mass" = MyDF$Prey.mass)

print("Calculating the needed results...", quote = FALSE)
results = ddply(subDF, .(Feeding.type.X.Predator.lifestage.X.Location), summarize,
              intercept = lm(log10(Predator.mass)~log10(Prey.mass))$coef[1],
              slope = lm(log10(Predator.mass)~log10(Prey.mass))$coef[2], 
              r.squared = summary(lm(log10(Predator.mass)~log10(Prey.mass)))$r.squared,
              f.statistic = as.numeric(glance(lm(log10(Predator.mass)~log10(Prey.mass)))[4]),
              p.value = summary(lm(log10(Predator.mass)~log10(Prey.mass)))$coefficients[8])

print("Writing the results into a csv file...", quote = FALSE)
write.csv(results, "../results/PP_Regress_loc_Results.csv", row.names = FALSE)

print("Done!", quote = FALSE)
**********************************************************************

Testing PP_Regress_loc.R...

Output (only first 500 characters): 

**********************************************************************
[1] Calculating the needed results...
[1] Writing the results into a csv file...
[1] Done!

**********************************************************************

Code ran without errors

Time consumed = 1.83645s

======================================================================
Inspecting script file DataWrang.R...

File contents are:
**********************************************************************
#!/usr/bin/env R

################################################################
################## Wrangling the Pound Hill Dataset ############
################################################################

############# Load the dataset ###############
# header = false because the raw data don't have real headers
MyData <- as.matrix(read.csv("../data/PoundHillData.csv",header = F)) 

# header = true because we do have metadata headers
MyMetaData <- read.csv("../data/PoundHillMetaData.csv",header = T, sep=";", stringsAsFactors = F)

############# Inspect the dataset ###############
head(MyData)
dim(MyData)
str(MyData)

############# Transpose ###############
# To get those species into columns and treatments into rows 
MyData <- t(MyData) 
head(MyData)
dim(MyData)

############# Replace species absences with zeros ###############
MyData[MyData == ""] = 0

############# Convert raw matrix to data frame ###############

TempData <- as.data.frame(MyData[-1,],stringsAsFactors = F) #stringsAsFactors = F is important!
colnames(TempData) <- MyData[1,] # assign column names from original data

############# Convert from wide to long format  ###############
library(reshape2) # load the reshape2 package

#?melt - check out the melt function

MyWrangledData <- melt(TempData, id=c("Cultivation", "Block", "Plot", "Quadrat"), variable.name = "Species", value.name = "Count")

MyWrangledData[, "Cultivation"] <- as.factor(MyWrangledData[, "Cultivation"])
MyWrangledData[, "Block"] <- as.factor(MyWrangledData[, "Block"])
MyWrangledData[, "Plot"] <- as.factor(MyWrangledData[, "Plot"])
MyWrangledData[, "Quadrat"] <- as.factor(MyWrangledData[, "Quadrat"])
MyWrangledData[, "Count"] <- as.integer(MyWrangledData[, "Count"])

str(MyWrangledData)
head(MyWrangledData)
dim(MyWrangledData)

############# Exploring the data (extend the script below)  ###############
**********************************************************************

Testing DataWrang.R...

Output (only first 500 characters): 

**********************************************************************
     V1                     V2        V3        V4        V5        V6       
[1,] "Cultivation"          "october" "october" "october" "october" "october"
[2,] "Block"                "a"       "a"       "a"       "a"       "a"      
[3,] "Plot"                 "1"       "1"       "1"       "1"       "1"      
[4,] "Quadrat"              "Q1"      "Q2"      "Q3"      "Q4"      "Q5"     
[5,] "Achillea millefolium" "4"       "8"       "3"       "20"      "6"      
[6,] "Agrostis gigantea"    ""   
**********************************************************************

Code ran without errors

Time consumed = 0.32457s

======================================================================
Inspecting script file run_Vectorize.sh...

File contents are:
**********************************************************************
#!/bin/bash
# Author: Hovig Artinian ha819@imperial.ac.uk
# Script: run_Vectorize.sh
# Desc: runs Vectorize1.R, Vectorize1.py, Vectorize2.R, Vectorize2.py scripts
# Arguments: None
# Date: Oct 2019

# First, run the scripts
echo -e "\nRunning Vectorize1.R...\n"
Rscript Vectorize1.R
if [ $? ] # If script runs successfully, the stored value of $? will be 0, which makes the if statement TRUE
then
    echo -e "\nScript ran successfully!\n"
else
    echo -e "\nScript failed to run :(\n"
fi

echo -e "Running Vectorize1.py...\n"
python3 Vectorize1.py
if [ $? ]
then
    echo -e "\nScript ran successfully!\n"
else
    echo -e "\nScript failed to run :(\n"
fi

echo -e "Running Vectorize2.R...\n"
Rscript Vectorize2.R
if [ $? ]
then
    echo -e "\nScript ran successfully!\n"
else
    echo -e "\nScript failed to run :(\n"
fi

echo -e "Running Vectorize2.py...\n"
python3 Vectorize2.py
if [ $? ]
then
    echo -e "\nScript ran successfully!\n"
else
    echo -e "\nScript failed to run :(\n"
fi

echo "Now that we have ran the scripts, let's compare their computational speeds (in seconds)..."
printf "SumAllElements function in the R script Vectorize1.R        : " && cat ../data/Vectorize1_R.txt | head -1
printf "Built-in sum function in the R script Vectorize1.R          : " && cat ../data/Vectorize1_R.txt | tail -1
printf "SumAllElements function in the Python script Vectorize1.py  : " && cat ../data/Vectorize1_py.txt | head -1
printf "Built-in sum function in the Python script Vectorize1.py    : " && cat ../data/Vectorize1_py.txt | tail -1
printf "Stochrick function in the R script Vectorize2.R             : " && cat ../data/Vectorize2_R.txt | head -1
printf "Stochrickvect function in the R script Vectorize2.R         : " && cat ../data/Vectorize2_R.txt | tail -1
printf "Stochrick function in the Python script Vectorize2.py       : " && cat ../data/Vectorize2_py.txt | head -1
printf "Stochrickvect function in the Python script Vectorize2.py   : " && cat ../data/Vectorize2_py.txt | tail -1
echo -e "\n"
**********************************************************************

Testing run_Vectorize.sh...

Output (only first 500 characters): 

**********************************************************************

Running Vectorize1.R...

[1] Using loops, the time taken is:
   user  system elapsed 
  0.088   0.000   0.088 
[1] Using the in-built vectorized function, the time taken is:
   user  system elapsed 
  0.000   0.000   0.002 

Script ran successfully!

Running Vectorize1.py...

Using loops, the time taken is:
0.226
Using the in-built vectorized function, the time taken is:
0.001

Script ran successfully!

Running Vectorize2.R...

[1] Non-vectorized Stochastic Ricker takes 0.242 seconds.
[1] Vector
**********************************************************************

Code ran without errors

Time consumed = 1.86151s

======================================================================
Inspecting script file MyBars.R...

File contents are:
**********************************************************************
#!/usr/bin/env R

a <- read.table("../data/Results.txt", header = TRUE)
head(a)

a$ymin <- rep(0, dim(a)[1]) # append a column of zeros

library(ggplot2)

# Print the first linerange
p <- ggplot(a)
p <- p + geom_linerange(data = a, aes(
                          x = x,
                          ymin = ymin,
                          ymax = y1,
                          size = (0.5)
                          ),
                        colour = "#E69F00",
                        alpha = 1/2, show.legend = FALSE)

# Print the second linerange
p <- p + geom_linerange(data = a, aes(
                          x = x,
                          ymin = ymin,
                          ymax = y2,
                          size = (0.5)
                          ),
                        colour = "#56B4E9",
                        alpha = 1/2, show.legend = FALSE)

# Print the third linerange:
p <- p + geom_linerange(data = a, aes(
                          x = x,
                          ymin = ymin,
                          ymax = y3,
                          size = (0.5)
                          ),
                        colour = "#D55E00",
                        alpha = 1/2, show.legend = FALSE)

# Annotate the plot with labels:
p <- p + geom_text(data = a, aes(x = x, y = -500, label = Label))

# now set the axis labels, remove the legend, and prepare for bw printing
p <- p + scale_x_continuous("My x axis",
                            breaks = seq(3, 5, by = 0.05)) + 
                            scale_y_continuous("My y axis") + 
                            theme_bw() + 
                            theme(legend.position = "none") 
pdf("../results/MyBars.pdf")
print(p)
graphics.off()
**********************************************************************

Testing MyBars.R...

Output (only first 500 characters): 

**********************************************************************
         x   y1   y2 y3 Label
1 3.515424 4320 4320  0  <NA>
2 3.533984 2160 2160  0  <NA>
3 3.557647 4320 4320  0  <NA>
4 3.569953 4320 4320  0  <NA>
5 3.578984 8640 8640  0  <NA>
6 3.585665 2160 2160  0  <NA>

**********************************************************************

Encountered error (or warning):
Warning message:
Removed 91 rows containing missing values (geom_text). 

======================================================================
======================================================================
Finished running scripts

Ran into 2 errors

======================================================================
======================================================================

FINISHED WEEKLY ASSESSMENT

Current Points for the Week = 99.5

NOTE THAT THESE ARE POINTS, NOT MARKS FOR THE WEEK!